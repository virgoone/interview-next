---
title: AI 基础核心问题
---

# AI 基础核心问题

## 主问题：LLM、Agent、MCP 分别是什么？

### 核心回答

- **LLM（大语言模型）**：基于 Transformer 架构，经海量文本预训练的超大规模深度学习模型，核心能力是理解文本、生成内容、逻辑推理，支持零样本/少样本学习，参数规模达数十亿至数万亿级，典型代表有 GPT 系列、BERT、LLaMA。

- **Agent（AI 智能体）**：以 LLM 为"大脑"的自主执行系统，核心是"目标导向+自主闭环"，通过感知环境、拆解任务、调用工具、记忆反馈完成复杂任务，区别于传统被动响应式工具，架构包含 LLM 核心、感知模块、工具调用层、记忆系统、执行引擎。

- **MCP（模型通信协议）**：Anthropic 推出的开放协议，本质是 AI 与外部工具/数据源的"标准化接口"，解决不同工具接口碎片化问题，比传统 API 更适配 AI 的理解与调用逻辑，降低 Agent 对接外部系统的成本。

### 延伸问题-回答

1. **延伸问题**：如何评估 LLM 性能？

回答：从四大核心维度评估——①生成质量（流畅性、逻辑连贯性）；②事实准确性（避免幻觉）；③任务完成度（是否满足具体需求）；④泛化性（跨场景适配能力）。结合人工评估与基准测试（如 GLUE、SuperGLUE、MMLU），不同任务侧重不同，例如问答类重点看事实准确率，创作类重点看流畅性。

2. **延伸问题**：如何减轻 LLM 的幻觉现象？

回答：三大关键手段——①提示工程：明确指令要求"基于事实回答，未知则说明"；②检索增强（RAG）：让模型先从可靠知识库检索信息，再基于检索结果生成；③工具调用：强制模型通过 API 调用实时/权威数据源（如数据库、官方接口），避免凭空捏造。

3. **延伸问题**：AI Agent 的记忆系统如何设计？

回答：采用"短期+长期"双层记忆架构——①短期记忆：通过对话上下文传递，每次调用 LLM 时携带近期交互信息，保障多轮对话连贯性；②长期记忆：用向量数据库存储历史关键信息（如用户偏好、任务结果），通过相似度检索召回相关内容，避免重复信息或遗忘核心细节。

4. **延伸问题**：MCP 与 Agent 是什么关系？

回答：MCP 是 Agent 与外部世界交互的"通信桥梁"，Agent 是 MCP 的"核心使用者"：没有 MCP，Agent 需适配不同工具的个性化接口，开发效率低；没有 Agent，MCP 仅为单纯协议，无法发挥"自主调用"的价值。两者结合让 Agent 能高效对接海量工具，实现"思考-执行"闭环。

> （注：文档部分内容可能由 AI 生成）

